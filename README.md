# Scalable Speaker Grouping using Speech and Image feature from animation videos

本项目是 [Chat凉宫春日](https://github.com/LC1332/Chat-Haruhi-Suzumiya) 社区的一个子项目，意在建立一个更好的pipeline，能够批量地分离视频的数据，为视频中的每一句话标记上对应的角色，便于给其他的AI模型提供多模态的训练数据。

【配图】

本项目是一个在建的项目，并且我们也在招募新的开发者加入，如果你对这个项目感兴趣，欢迎到我的[知乎主页](https://www.zhihu.com/people/cheng-li-47)或者发送你的微信号到 chengli.thu@gmail.com 联系我。

---

- [引言](#引言)
- [TODO和成员招募](#TODO和成员招募)

---

# 引言


# TODO和成员招募


## 待聚类的输入数据格式确定
这个和scixing讨论下？
- 这里要确定最终进入聚类前的数据格式（模型无关）
  - 每一条数据应该包括  标签、一张图、音频
  - 最好是接近密集存储的，实在不行也可以打成zip
- 确定从什么样的数据可以切分到这样的数据
  - 现在想一想输入至少要 原始视频、字幕文件、标注后的csv文件
- 确定标注数据的格式
  - 感觉是csv比较合适
- 从之前的代码中整理出可以运行的部分
  - 确定好之后，把之前的《凉宫春日》和《亮剑》整理成对应的格式
  - 应该加起来有7个左右标注后的视频
- 先打包成最终聚类前的数据格式

## 预标注工具的确认
寻找两个待标注的视频，确认字幕和视频是同步的
- 设想流程还是 srt2csv先，
- 然后进行简单的人物标注后 csv
- 根据部分标注的csv，KNN出基础的结果，出新的csv
- 人工进行进一步标注
- 返回前面那个工具进行最终切分

我们假设这个任务是在整套高级的聚类算法形成之前做的研究性标注
当然如果接口预留得好，也可以最终接入最终的算法

这个任务 鲁叔和scixing进行 初步的代码整理，之后交给肖君枫以及其他数据集负责同学进行测试
可以有同学接受这个部分写得更强一些

## 声纹特征的抽取
待报名
- 跑通之前项目的声纹提取
- 扩展声纹提取到batch抽取
- 确定声纹提取的接口比如features =  extract_feature( file_names)
- 调研中、英、日是否有特别的声纹识别模型
- 在已经标注的数据上，测试各个模型的交叉验证准确率
这个如果没人就先沿用之前的特征

## 图片特征的抽取
待报名
- 跑通CLIP里面的ViTs抽取
- 扩展到batch抽取（其实我们之前留了代码）
- 确定接口 比如 features = extract_features( file_names )
- 在已经标注的数据上，测试各个模型的交叉验证准确率

这个如果没人就沿用之前的vits或者看之前参考项目