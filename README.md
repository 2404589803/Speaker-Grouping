# Scalable Speaker Grouping using Speech and Image feature from animation videos

本项目是 [Chat凉宫春日](https://github.com/LC1332/Chat-Haruhi-Suzumiya) 社区的一个子项目，意在建立一个更好的pipeline，能够批量地分离视频的数据，为视频中的每一句话标记上对应的角色，便于给其他的AI模型提供多模态的训练数据。

【配图】

本项目是一个在建的项目，并且我们也在招募新的开发者加入，如果你对这个项目感兴趣，欢迎到我的[知乎主页](https://www.zhihu.com/people/cheng-li-47)或者发送你的微信号到 chengli.thu@gmail.com 联系我。

---

- [引言](#引言)
- [TODO和成员招募](#TODO和成员招募)

---

# 引言

随着语言模型和Stable Diffusion等很多新的AI模型的出现，我们逐渐意识到文本数据，以及文本和其他模态结合的数据是很重要的。并且在[Chat凉宫春日](https://github.com/LC1332/Chat-Haruhi-Suzumiya)中，我们验证了使用现有ip的数据，可以构造一个更生动的角色扮演。现在模型训练时使用的文本数据或者图文数据往往都是从互联网或者书本中抓取的。视频数据提供了更丰富的文本和其他模态结合的数据，却因为较少标注而较难理解。

在这个前提下，我们希望能够对视频数据进行更好的标注。事实上字幕数据已经能够提供足够的文本信息。然而，对于过往的影视作品，有一个很大的问题是字幕的数据并没有进行说话人的标注，这使得语言模型在理解字幕数据的时候会遇到很大的困难。因此，本项目希望在给定视频，以及可选的字幕数据的情况下，能够自动地对视频进行分割，并且标注上说话人的信息。这些数据在之后可以被进一步应用于声纹识别，声音合成，动漫角色识别，跨模态的语言模型训练，跨模态的角色扮演等模型的训练。

【配图:过往的工作流，原始CSV->部分标注->KNN->自动标注->人工整理】

【配图:过往的工作流，whisper识别->原始CSV->部分标注->KNN->自动标注->人工整理】

在Chat凉宫春日中，我们已经尝试了一个简单的方法，先对部分字幕的句子进行人工的角色标注，然后利用K近邻算法对剩余的句子进行自动标注。这个方法在一定程度上提高了标注的效率。但是在实践中，这个方法有很大的人工成本，在后续的人工整理中，标注者需要播放整个视频，对标注结果进行修正和分析。这个过程是非常耗时的。因此，我们希望能够通过更好的算法，减少人工标注的工作量。

我们注意到使用之前的工作流有一些问题: 1. 声纹识别的特征的准确率有限。这是由于目前并没有超大量的公开数据对声纹识别进行训练。 2. 有一些字幕对应的句子并不适合抽取声纹特征，如较短的句子，叠加了复杂背景噪声的句子。 3. 在之前的工作流中，并没有利用到视频的信息。对于较为简单的动画来说，一些句子对应的画面中往往只有一个角色。这个信息可以帮助我们更好地进行说话人的识别。

由此，我们提出了一套新的方法来进行说话人的识别与聚类。1. 我们的方法将同时利用声音和图像的特征进行聚类。 2. 我们的方法是基于学习的，整个方法会在一定数量的视频数据上进行训练，并确定声音和图像的一个置信度模型，对于置信度较高的句子，先行进行聚类。置信度较低的句子后聚类，并且不会因为一些质量较差的句子，把多个类错误地聚合在一起。 3. 标注者只要对聚类后的结果进行较少的人工整理，并且不需要观看整个视频，就可以得到完整的说话人标注，这使得我们规模化地标注视频的说话人数据成为可能。


# TODO和成员招募


## 待聚类的输入数据格式确定
这个和scixing讨论下？
- 这里要确定最终进入聚类前的数据格式（模型无关）
  - 每一条数据应该包括  标签、一张图、音频
  - 最好是接近密集存储的，实在不行也可以打成zip
- 确定从什么样的数据可以切分到这样的数据
  - 现在想一想输入至少要 原始视频、字幕文件、标注后的csv文件
- 确定标注数据的格式
  - 感觉是csv比较合适
- 从之前的代码中整理出可以运行的部分
  - 确定好之后，把之前的《凉宫春日》和《亮剑》整理成对应的格式
  - 应该加起来有7个左右标注后的视频
- 先打包成最终聚类前的数据格式

## 预标注工具的确认
寻找两个待标注的视频，确认字幕和视频是同步的
- 设想流程还是 srt2csv先，
- 然后进行简单的人物标注后 csv
- 根据部分标注的csv，KNN出基础的结果，出新的csv
- 人工进行进一步标注
- 返回前面那个工具进行最终切分

我们假设这个任务是在整套高级的聚类算法形成之前做的研究性标注
当然如果接口预留得好，也可以最终接入最终的算法

这个任务 鲁叔和scixing进行 初步的代码整理，之后交给肖君枫以及其他数据集负责同学进行测试
可以有同学接受这个部分写得更强一些

## 声纹特征的抽取
待报名
- 跑通之前项目的声纹提取
- 扩展声纹提取到batch抽取
- 确定声纹提取的接口比如features =  extract_feature( file_names)
- 调研中、英、日是否有特别的声纹识别模型
- 在已经标注的数据上，测试各个模型的交叉验证准确率
这个如果没人就先沿用之前的特征

## 图片特征的抽取
待报名
- 跑通CLIP里面的ViTs抽取
- 扩展到batch抽取（其实我们之前留了代码）
- 确定接口 比如 features = extract_features( file_names )
- 在已经标注的数据上，测试各个模型的交叉验证准确率

这个如果没人就沿用之前的vits或者看之前参考项目